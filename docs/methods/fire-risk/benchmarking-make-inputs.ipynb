{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "156b191e-ed3d-4dbb-8044-dff4f50124db",
   "metadata": {},
   "source": [
    "# Create a dataset for benchmarking\n",
    "Combine three datasets:\n",
    "1. The processed Open Climate Risk burn probability data\n",
    "2. The original burn probability data from Riley et al. (to create a \"non-burnable\" mask)\n",
    "3. Historical fire perimeters\n",
    "\n",
    "Note, this script has not been optimized for performance. It requires at least 400GB of memory (I used `m8g.48xlarge`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2710419c-b83e-4f73-ab6c-aaad0bb35f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "import icechunk\n",
    "import numpy as np\n",
    "import rasterio.features\n",
    "import xarray as xr\n",
    "\n",
    "# import seaborn as sns    # plotting\n",
    "from ocr import catalog  # for the riley data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1889aac7-9dc8-467c-9ddb-4328f5111670",
   "metadata": {},
   "source": [
    "# Read in and pre-process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b36f2c-525e-4811-8e11-9b370a53c329",
   "metadata": {},
   "source": [
    "## Open Climate Risk burn probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f13edad4-8a9d-48c5-b8af-84919282b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '0.8.0'\n",
    "setup = 'production'\n",
    "\n",
    "storage = icechunk.s3_storage(\n",
    "    bucket='carbonplan-ocr',\n",
    "    prefix=f'output/fire-risk/tensor/{setup}/v{version}/ocr.icechunk',\n",
    "    from_env=True,\n",
    ")\n",
    "repo = icechunk.Repository.open(storage)\n",
    "session = repo.readonly_session('main')\n",
    "\n",
    "ds = xr.open_zarr(session.store, consolidated=False, zarr_format=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311c0796-cdfd-4342-83d9-d8a454695aeb",
   "metadata": {},
   "source": [
    "## Riley et al. burn probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c8e78-80fb-48a6-8351-577cbabe55b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- read in\n",
    "riley_2011_30m_4326 = catalog.get_dataset('riley-et-al-2025-2011-30m-4326').to_xarray()[['BP']]\n",
    "# there are slight mismatches with the coordinates in `ds`\n",
    "# interpolate riley data to exactly match ds coordinates\n",
    "riley_interp = riley_2011_30m_4326.interp(\n",
    "    latitude=ds.latitude, longitude=ds.longitude, method='nearest'\n",
    ")\n",
    "# assign coordinates\n",
    "ds['riley_BP_2011'] = riley_interp.BP\n",
    "# create burnable mask\n",
    "ds['riley_burnable_mask'] = xr.where(ds['riley_BP_2011'] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac848a0-2048-4575-8d6b-3c7dfb6e0bc2",
   "metadata": {},
   "source": [
    "## Historical fire perimeters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eca2993-074f-4d17-8c6f-cc2f5003cf15",
   "metadata": {},
   "source": [
    "### + Filter the data\n",
    "The Inter Agency Fire Perimeter History dataset includes small fires (where reported fire size limits are set by each reporting agency) and prescribed burns. \n",
    "\n",
    "We filter out small fires in an effort to omit prescribed and more manageable fires. Based on the National Interagency Fire Center [data](https://www.nifc.gov/fire-information/statistics/prescribed-fire), mean prescribed burns are around 30-50 acres (total fires / total acres). To omit most of these burns, we filter out all fire perimeters with an area less than 75 acres. (Note that there does not appear to be an input marking prescribed burns in the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13df96fa-8484-4e9f-8af6-70ea6cf9ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- read in historical fire perimeter data (note, it can take a couple mins to load)\n",
    "fp_path = 's3://carbonplan-ocr/evaluation/'\n",
    "fp_name = 'InterAgencyFirePerimeterHistory_All_Years_View_-104997095188071827.gpkg'\n",
    "gdf = gpd.read_file(os.path.join(fp_path, fp_name))\n",
    "# convert CRS\n",
    "gdf = gdf.to_crs('EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1a71129-5661-4255-b1be-db79b44395db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- filter data\n",
    "min_acres = 75\n",
    "gdf = gdf[gdf['GIS_ACRES'] > min_acres]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9309412a-e096-44d6-a0b3-c98c2754dc73",
   "metadata": {},
   "source": [
    "#### Add burn sum and mask and merge with ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c0c5a06-6170-493d-be24-3aa7f7ab5146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- define transform for rasterization\n",
    "# Assuming lon/lat are 1D arrays\n",
    "transform = rasterio.transform.from_bounds(\n",
    "    ds.longitude.min(),\n",
    "    ds.latitude.min(),\n",
    "    ds.longitude.max(),\n",
    "    ds.latitude.max(),\n",
    "    len(ds.longitude),\n",
    "    len(ds.latitude),\n",
    ")\n",
    "\n",
    "# --- compute burn sum\n",
    "# create (geometry, value) tuples\n",
    "shapes = [(geom, 1) for geom in gdf.geometry]\n",
    "\n",
    "# burn all at once\n",
    "burn_sum = rasterio.features.rasterize(\n",
    "    [(geom, 1) for geom in gdf.geometry],\n",
    "    out_shape=(len(ds.latitude), len(ds.longitude)),\n",
    "    transform=transform,\n",
    "    all_touched=True,\n",
    "    dtype=np.uint16,  # allows counts > 255\n",
    "    merge_alg=rasterio.features.MergeAlg.add,  # sum overlapping polygons\n",
    ")\n",
    "\n",
    "# add to dataset\n",
    "ds['burn_sum'] = (('latitude', 'longitude'), burn_sum)\n",
    "\n",
    "# get burn mask\n",
    "ds['burn_mask'] = xr.where(ds['burn_sum'] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4bdedc-daf9-4dcb-99f4-f8cbeb93c154",
   "metadata": {},
   "source": [
    "# Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e976fd8-82bd-468d-8cf4-55955594b9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- delete everything we don't need\n",
    "del burn_sum, shapes, transform, gdf, riley_interp, riley_2011_30m_4326\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eca2d79-a531-430b-a368-df62875c1470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- rechunk\n",
    "for name, var in ds.data_vars.items():\n",
    "    ds[name] = var.chunk({'latitude': 6000, 'longitude': 4500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b66a185-131b-49cb-a4ed-f37a05c69f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/coiled/env/lib/python3.13/site-packages/zarr/api/asynchronous.py:244: ZarrUserWarning: Consolidated metadata is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0xf0c17606fa60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_path = 's3://carbonplan-ocr/evaluation/'\n",
    "savename = 'benchmarking-input-dat.zarr'\n",
    "\n",
    "# write to S3\n",
    "ds.to_zarr(\n",
    "    os.path.join(s3_path, savename),\n",
    "    mode='w',  # overwrite (use \"a\" to append)\n",
    "    compute=True,\n",
    "    storage_options={'anon': False},  # set to True if public bucket\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810674fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bb9c91-b011-4c50-9a7c-802e57cbf8f3",
   "metadata": {},
   "source": [
    "## Compute quartiles for proportional plot\n",
    "Restart kernel\n",
    "\n",
    "Note that we omit burn probabilities of zero for this analysis because east of the 98th meridian BP=0 accounts for more than 20% of all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b190e3a-db6f-422f-9e0c-0c7d4a813505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0xf534fff0ead0>\n",
      "Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0xf534ffe26390>, 151.370221169)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0xf534fff0ca50>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0xf534fff0c7d0>\n",
      "Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0xf534ffe265d0>, 151.372040247)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0xf534fff0c410>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0xf534fff0ed50>\n",
      "Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0xf534ffe26810>, 151.376278934)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0xf536b41c3390>\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "import icechunk\n",
    "import numpy as np\n",
    "import rasterio.features\n",
    "\n",
    "# import seaborn as sns    # plotting\n",
    "import s3fs\n",
    "import xarray as xr\n",
    "\n",
    "from ocr import catalog  # for the riley data\n",
    "\n",
    "# --- read in dat\n",
    "s3_path = 's3://carbonplan-ocr/evaluation/'\n",
    "savename = 'benchmarking-input-dat.zarr'\n",
    "ds = xr.open_zarr(os.path.join(s3_path, savename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "794e305a-b6c0-4c1c-bfb3-5d913eab6bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- filter to four slices\n",
    "#     (CONUS, west, east, testbox) and later (all data, non-burnable)\n",
    "slicenames = {\n",
    "    'testbox': {'minlat': 42.7, 'maxlat': 46.3, 'minlon': -116.8, 'maxlon': -112.8},\n",
    "    'CONUS': None,\n",
    "    'West of -98': {'maxlon': -98},\n",
    "    'East of -98': {'minlon': -98},\n",
    "}\n",
    "\n",
    "outdict = {}  # to hold outputs\n",
    "for slc_key, slc_val in slicenames.items():\n",
    "    if slc_key == 'testbox':\n",
    "        outdict[slc_key] = ds.sel(\n",
    "            latitude=slice(slc_val['maxlat'], slc_val['minlat']),\n",
    "            longitude=slice(slc_val['minlon'], slc_val['maxlon']),\n",
    "        )\n",
    "    elif slc_key == 'CONUS':\n",
    "        outdict[slc_key] = ds.copy()\n",
    "\n",
    "    elif slc_key == 'West of -98':\n",
    "        outdict[slc_key] = ds.where(ds['longitude'] < slc_val['maxlon'], drop=True)\n",
    "\n",
    "    elif slc_key == 'East of -98':\n",
    "        outdict[slc_key] = ds.where(ds['longitude'] >= slc_val['minlon'], drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d41f4633-8ee4-41b3-be0d-c5daf0f76b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now solving: testbox\n",
      "Now solving: CONUS\n",
      "Now solving: West of -98\n",
      "Now solving: East of -98\n"
     ]
    }
   ],
   "source": [
    "# --- FAIRLY MEMORY INTENSIVE (~400 GB...) ---\n",
    "# --- split the dataset into 5 equal-area burn probability classes and compute expected vs observed burn proportions\n",
    "#     assume each pixel has the same area\n",
    "#\n",
    "#     Note, this builds on the dataset created in Benchmark 1\n",
    "#\n",
    "save_on = True  # whether to save the data\n",
    "\n",
    "for dsname, dsslice in outdict.items():\n",
    "    # track progress\n",
    "    print(f'Now solving: {dsname}')\n",
    "\n",
    "    # pull out dat\n",
    "    dsslice = outdict[dsname]\n",
    "    bp = dsslice['bp_2011']\n",
    "    bp_nonzero = bp.where(bp > 0)\n",
    "    burned = dsslice['burn_mask']\n",
    "\n",
    "    # --- create quantile edges for 5 equal-area (equal-count) classes\n",
    "    q_edges = np.linspace(0, 1, 6)  # 5 bins => 6 edges\n",
    "    bp_quantiles = bp_nonzero.quantile(q_edges, dim=None).compute()\n",
    "    edges = bp_quantiles.values\n",
    "\n",
    "    # assign each pixel to a burn probability class using digitize\n",
    "    # we broadcast bp_quantiles as edges\n",
    "    def digitize_chunk(chunk, edges):\n",
    "        return xr.DataArray(\n",
    "            np.digitize(chunk, edges, right=True) - 1,\n",
    "            dims=chunk.dims,\n",
    "            coords=chunk.coords,\n",
    "        )\n",
    "\n",
    "    bp_class = xr.map_blocks(digitize_chunk, bp_nonzero, kwargs={'edges': edges})\n",
    "    bp_class.name = 'bp_class'\n",
    "\n",
    "    # --- bring bpclass into memory and get expected vs observed proportions\n",
    "    total_bp_sum = bp_nonzero.sum()\n",
    "    total_burned_sum = (burned == 1).sum()\n",
    "\n",
    "    def masked_sum(var, cond):\n",
    "        return var.where(cond).sum()\n",
    "\n",
    "    expected_props = []\n",
    "    observed_props = []\n",
    "    # (for troubleshoot)\n",
    "    expected_sum = []  # this should be the same value for all cases (observed sum can vary)\n",
    "\n",
    "    for i in range(5):\n",
    "        cond = (bp_nonzero >= edges[i]) & (bp_nonzero < edges[i + 1])\n",
    "        expected_sum.append(cond.sum())\n",
    "        expected_props.append(masked_sum(bp_nonzero, cond) / total_bp_sum)\n",
    "        observed_props.append(masked_sum(burned == 1, cond) / total_burned_sum)\n",
    "\n",
    "    expected_props = xr.concat(expected_props, dim='bp_class').compute()\n",
    "    observed_props = xr.concat(observed_props, dim='bp_class').compute()\n",
    "    expected_sum = xr.concat(expected_sum, dim='bp_class').compute()\n",
    "\n",
    "    # check that expected bins are of equal size\n",
    "    assert np.isclose(expected_sum.max(), expected_sum.min()), 'Expected sums are not equivalent'\n",
    "    # check that both sum to 1\n",
    "    assert np.isclose(expected_props.sum(), 1.0, atol=1e-02), 'Expected proportions do not sum to 1'\n",
    "    assert np.isclose(observed_props.sum(), 1.0, atol=1e-02), 'Observed proportions do not sum to 1'\n",
    "\n",
    "    # rename data and combine\n",
    "    expected_props = expected_props.rename('bp2011_expected_burn_proportion')\n",
    "    observed_props = observed_props.rename('bp2011_observed_burn_proportion')\n",
    "    espected_sum = expected_sum.rename('bp2011_bpclass_sum')\n",
    "    tmpds_props = xr.merge([expected_props, observed_props, expected_sum])\n",
    "    tmpdf_props = tmpds_props.to_dataframe()\n",
    "    tmpdf_props = tmpdf_props.reset_index()\n",
    "    tmpdf_props['bp_class'] = tmpdf_props['bp_class'] + 1\n",
    "\n",
    "    # save\n",
    "    if save_on:\n",
    "        s3 = s3fs.S3FileSystem()\n",
    "        path = f's3://carbonplan-ocr/evaluation/benchmarking-processed/{dsname}_burnclass_proportions.parquet'\n",
    "        with s3.open(path, 'wb') as f:\n",
    "            tmpdf_props.to_parquet(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "209a6539-2c0a-4173-8a4d-7e8c56715136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now solving: testbox\n",
      "Now solving: CONUS\n",
      "Now solving: West of -98\n",
      "Now solving: East of -98\n"
     ]
    }
   ],
   "source": [
    "# --- FAIRLY MEMORY INTENSIVE (~400 GB...) ---\n",
    "#\n",
    "# --- [ REPEAT FOR NON-BURNABLE ] ------------\n",
    "#\n",
    "# --- split the dataset into 5 equal-area burn probability classes and compute expected vs observed burn proportions\n",
    "#     assume each pixel has the same area\n",
    "#\n",
    "#     Note, this builds on the dataset created in Benchmark 1\n",
    "#\n",
    "save_on = True  # whether to save the data\n",
    "\n",
    "for dsname, dsslice in outdict.items():\n",
    "    # track progress\n",
    "    print(f'Now solving: {dsname}')\n",
    "\n",
    "    # pull out dat\n",
    "    dsslice = outdict[dsname]\n",
    "    bp = dsslice['bp_2011'].where(dsslice['riley_burnable_mask'] == 0)\n",
    "    bp_nonzero = bp.where(bp > 0)\n",
    "    burned = dsslice['burn_mask'].where(dsslice['riley_burnable_mask'] == 0)\n",
    "\n",
    "    # --- create quantile edges for 5 equal-area (equal-count) classes\n",
    "    q_edges = np.linspace(0, 1, 6)  # 5 bins => 6 edges\n",
    "    bp_quantiles = bp_nonzero.quantile(q_edges, dim=None).compute()\n",
    "    edges = bp_quantiles.values\n",
    "\n",
    "    # assign each pixel to a burn probability class using digitize\n",
    "    # we broadcast bp_quantiles as edges\n",
    "    def digitize_chunk(chunk, edges):\n",
    "        return xr.DataArray(\n",
    "            np.digitize(chunk, edges, right=True) - 1,\n",
    "            dims=chunk.dims,\n",
    "            coords=chunk.coords,\n",
    "        )\n",
    "\n",
    "    bp_class = xr.map_blocks(digitize_chunk, bp_nonzero, kwargs={'edges': edges})\n",
    "    bp_class.name = 'bp_class'\n",
    "\n",
    "    # --- bring bpclass into memory and get expected vs observed proportions\n",
    "    total_bp_sum = bp_nonzero.sum()\n",
    "    total_burned_sum = (burned == 1).sum()\n",
    "\n",
    "    def masked_sum(var, cond):\n",
    "        return var.where(cond).sum()\n",
    "\n",
    "    expected_props = []\n",
    "    observed_props = []\n",
    "    # (for troubleshoot)\n",
    "    expected_sum = []  # this should be the same value for all cases (observed sum can vary)\n",
    "\n",
    "    for i in range(5):\n",
    "        cond = (bp_nonzero >= edges[i]) & (bp_nonzero < edges[i + 1])\n",
    "        expected_sum.append(cond.sum())\n",
    "        expected_props.append(masked_sum(bp_nonzero, cond) / total_bp_sum)\n",
    "        observed_props.append(masked_sum(burned == 1, cond) / total_burned_sum)\n",
    "\n",
    "    expected_props = xr.concat(expected_props, dim='bp_class').compute()\n",
    "    observed_props = xr.concat(observed_props, dim='bp_class').compute()\n",
    "    expected_sum = xr.concat(expected_sum, dim='bp_class').compute()\n",
    "\n",
    "    # check that expected bins are of equal size\n",
    "    assert np.isclose(expected_sum.max(), expected_sum.min()), 'Expected sums are not equivalent'\n",
    "    # check that both sum to 1\n",
    "    assert np.isclose(expected_props.sum(), 1.0, atol=1e-01), 'Expected proportions do not sum to 1'\n",
    "    assert np.isclose(observed_props.sum(), 1.0, atol=1e-01), 'Observed proportions do not sum to 1'\n",
    "\n",
    "    # rename data and combine\n",
    "    expected_props = expected_props.rename('bp2011_expected_burn_proportion')\n",
    "    observed_props = observed_props.rename('bp2011_observed_burn_proportion')\n",
    "    espected_sum = expected_sum.rename('bp2011_bpclass_sum')\n",
    "    tmpds_props = xr.merge([expected_props, observed_props, expected_sum])\n",
    "    tmpdf_props = tmpds_props.to_dataframe()\n",
    "    tmpdf_props = tmpdf_props.reset_index()\n",
    "    tmpdf_props['bp_class'] = tmpdf_props['bp_class'] + 1\n",
    "\n",
    "    # save\n",
    "    if save_on:\n",
    "        s3 = s3fs.S3FileSystem()\n",
    "        path = f's3://carbonplan-ocr/evaluation/benchmarking-processed/{dsname}_burnclass_proportions_NB.parquet'\n",
    "        with s3.open(path, 'wb') as f:\n",
    "            tmpdf_props.to_parquet(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
