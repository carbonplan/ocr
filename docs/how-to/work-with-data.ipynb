{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b2d893-5644-4474-a945-266137871e0b",
   "metadata": {},
   "source": [
    "# Access OCR Output Data\n",
    "\n",
    "This guide shows how to access OCR's wind-adjusted fire risk output data using [Icechunk](https://icechunk.io/en/stable/), a versioned data format for cloud-native geospatial data.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python environment with `xarray`, `icechunk`, `duckdb` and `lonboard` installed.\n",
    "\n",
    "## What you'll learn\n",
    "\n",
    "- How to open and inspect the fire risk raster dataset\n",
    "- How to work with specific variables and spatial subsets\n",
    "- How to open and subset the raster sampled building vector dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b01d25",
   "metadata": {},
   "source": [
    "## Raster / Xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c91eb49-4288-4bc1-82fe-17acfad580e4",
   "metadata": {},
   "source": [
    "###  Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175f4aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import icechunk\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ea8691",
   "metadata": {},
   "source": [
    "### Connect to the Icechunk repository\n",
    "\n",
    "OCR's production fire risk data is stored in an Icechunk repository on S3. We'll connect to version `v0.9.0` of the wind-adjusted fire risk output. For valid versions, check out the [OCR's GitHub release page](https://github.com/carbonplan/ocr/releases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e42c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure S3 storage for the Icechunk repository\n",
    "version = 'v0.13.1'\n",
    "storage = icechunk.s3_storage(\n",
    "    bucket='us-west-2.opendata.source.coop',\n",
    "    prefix=f'carbonplan/carbonplan-ocr/output/fire-risk/tensor/production/{version}/ocr.icechunk',\n",
    "    anonymous=True,\n",
    ")\n",
    "\n",
    "# Open the repository\n",
    "repo = icechunk.Repository.open(storage)\n",
    "\n",
    "# Create a read-only session on the main branch\n",
    "session = repo.readonly_session('main')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc340db",
   "metadata": {},
   "source": [
    "### Open the dataset with xarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5728cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the dataset\n",
    "ds = xr.open_dataset(session.store, engine='zarr', chunks={})\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc5dfff",
   "metadata": {},
   "source": [
    "### Explore the data variables\n",
    "\n",
    "The dataset contains wind-adjusted fire risk metrics. Let's examine the available variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30eee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all data variables\n",
    "print('Data variables:')\n",
    "for var in ds.data_vars:\n",
    "    print(f'  - {var}: {ds[var].attrs.get(\"long_name\", \"No description\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eabc582",
   "metadata": {},
   "source": [
    "### Select a spatial subset\n",
    "\n",
    "Extract data for a specific geographic region using coordinate slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e8e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Select data for California region\n",
    "california_subset = ds.sel(\n",
    "    latitude=slice(42, 32),  # Southern to Northern California\n",
    "    longitude=slice(-125, -114),  # Western to Eastern California\n",
    ")\n",
    "\n",
    "california_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2882fdb3",
   "metadata": {},
   "source": [
    "## Vector building dataset\n",
    "Next we will open and query the raster sampled building dataset stored in the `geoparquet` format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7e0d09",
   "metadata": {},
   "source": [
    "###  Import required libraries\n",
    "Here we'll import duckdb and load the spatial extension. The combination of `duckdb` spatial and `geoparquet` allows us to perform GIS queries that are beyond desktop GIS capabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ba3caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "duckdb.sql(\"\"\"INSTALL SPATIAL; LOAD SPATIAL; INSTALL HTTPFS; LOAD HTTPFS\"\"\")\n",
    "dataset_uri = f's3://us-west-2.opendata.source.coop/carbonplan/carbonplan-ocr/output/fire-risk/vector/production/{version}/geoparquet/buildings.parquet/**'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf198a4",
   "metadata": {},
   "source": [
    "### Examine the dataset\n",
    "- The SQL `describe` command shows us that the dataset contains raster sampled variables as well as geometry columns and regional identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e056c8-ac02-4249-a3c1-a39199d58807",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(f\"\"\"\n",
    "DESCRIBE\n",
    "SELECT\n",
    "   *\n",
    "FROM\n",
    "   read_parquet('{dataset_uri}', hive_partitioning = TRUE)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617ce1d8",
   "metadata": {},
   "source": [
    "### Load the first few rows\n",
    "Using the SQL `LIMIT` command, we can get just the first few rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f328dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(f\"\"\"\n",
    "SELECT\n",
    "   *\n",
    "FROM\n",
    "   read_parquet('{dataset_uri}', hive_partitioning = TRUE) LIMIT 5\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58715285",
   "metadata": {},
   "source": [
    "### Subset by state and county\n",
    "This geoparquet is partitioned by [state and county using FIPS codes](https://transition.fcc.gov/oet/info/maps/census/fips/fips.txt). \n",
    "\n",
    "Let's select data in LA County in California.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44304704",
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_FIPS_CODE = '06'\n",
    "LA_FIPS_CODE = '037'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd279fa",
   "metadata": {},
   "source": [
    "### Get a count of the number of records in LA County\n",
    "Using the `COUNT` SQL syntax, we can get the total number of entires in our query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc9a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(f\"\"\"\n",
    "SELECT\n",
    "   COUNT(*) AS LA_building_count\n",
    "FROM\n",
    "   read_parquet('{dataset_uri}', hive_partitioning = TRUE)\n",
    "WHERE\n",
    "   state_fips = '{CA_FIPS_CODE}'\n",
    "   AND county_fips = '{LA_FIPS_CODE}'\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b712c8a9",
   "metadata": {},
   "source": [
    "### Subset by bounding box\n",
    "Looks like there are about 3 million building polygons in our query. Let's subset that further.\n",
    "\n",
    "We can get a [bounding box (bbox) for an area around the Palisades fire](http://bboxfinder.com/#34.026381,-118.761864,34.152972,-118.466263).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cc7832",
   "metadata": {},
   "outputs": [],
   "source": [
    "palisades_bbox = (-118.761864, 34.026381, -118.466263, 34.152972)\n",
    "\n",
    "palisades_query = duckdb.sql(f\"\"\"\n",
    "SELECT\n",
    "   wind_risk_2011,\n",
    "   geometry\n",
    "FROM\n",
    "   read_parquet('{dataset_uri}', hive_partitioning = TRUE)\n",
    "WHERE\n",
    "   state_fips = '{CA_FIPS_CODE}'\n",
    "   AND county_fips = '{LA_FIPS_CODE}'\n",
    "   AND bbox.xmin BETWEEN {palisades_bbox[0]} AND {palisades_bbox[2]}\n",
    "   AND bbox.ymin BETWEEN {palisades_bbox[1]} AND {palisades_bbox[3]}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3205c879",
   "metadata": {},
   "source": [
    "### Visualize our query\n",
    "Next we'll use the python plotting library, [lonboard](https://developmentseed.org/lonboard/latest/) to visualize the wind informed risk in an interactive map.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed8747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lonboard import Map, PolygonLayer\n",
    "from lonboard.colormap import apply_continuous_cmap\n",
    "from matplotlib import colormaps\n",
    "\n",
    "layer = PolygonLayer.from_duckdb(\n",
    "    palisades_query,\n",
    "    get_fill_color=apply_continuous_cmap(\n",
    "        palisades_query.fetchdf()['wind_risk_2011'], colormaps['YlOrRd']\n",
    "    ),\n",
    "    pickable=True,\n",
    ")\n",
    "\n",
    "m = Map(layer, show_tooltip=True)\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr (3.13.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
