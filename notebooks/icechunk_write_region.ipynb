{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3346a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import warnings\n",
    "\n",
    "import dask\n",
    "import icechunk\n",
    "import matplotlib.style as mplstyle\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from distributed import Client\n",
    "from icechunk.distributed import merge_sessions\n",
    "\n",
    "from ocr.chunking_config import ChunkingConfig\n",
    "\n",
    "mplstyle.use('fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e286a92e-8a93-4fc3-bb57-4994a12d68b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=12)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b24b22-a9fa-4d47-96ff-4ccd3b07bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ChunkingConfig()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed78bfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = icechunk.s3_storage(\n",
    "    bucket='carbonplan-ocr',\n",
    "    prefix='input/fire-risk/tensor/USFS/RDS-2022-0016-02_all_vars_merge_icechunk',\n",
    "    from_env=True,\n",
    ")\n",
    "\n",
    "\n",
    "repo = icechunk.Repository.open(storage)\n",
    "session = repo.readonly_session('main')\n",
    "ds = xr.open_zarr(session.store, consolidated=False, chunks={})[['BP']]\n",
    "ds['BP'] = ds['BP'].astype('float32')\n",
    "ds['BP'].encoding = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ef6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_chunks = config.chunks\n",
    "template = xr.Dataset(config.ds.coords).drop_vars('spatial_ref')\n",
    "template['BP'] = xr.DataArray(\n",
    "    dask.array.zeros(\n",
    "        (config.ds.sizes['y'], config.ds.sizes['x']),\n",
    "        dtype='float32',\n",
    "        chunks=(config.chunks['y'], config.chunks['x']),\n",
    "    ),\n",
    "    dims=('y', 'x'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9938d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = icechunk.local_filesystem_storage(tempfile.TemporaryDirectory().name)\n",
    "repo = icechunk.Repository.create(storage)\n",
    "session = repo.writable_session('main')\n",
    "\n",
    "template.to_zarr(\n",
    "    session.store,\n",
    "    compute=False,\n",
    "    mode='w',\n",
    "    encoding={\n",
    "        'BP': {'chunks': ((config.chunks['y'], config.chunks['x'])), 'fill_value': np.nan}\n",
    "    },  # IMPORTANT\n",
    "    consolidated=False,\n",
    ")\n",
    "\n",
    "session.commit('template')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8db0dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commit_messages_ancestry(repo: icechunk.repository) -> list:\n",
    "    return [commit.message for commit in list(repo.ancestry(branch='main'))]\n",
    "\n",
    "\n",
    "@dask.delayed\n",
    "def insert_region(session: icechunk.Session, subset_ds: xr.Dataset):\n",
    "    subset_ds.to_zarr(\n",
    "        session.store,\n",
    "        region='auto',\n",
    "        consolidated=False,\n",
    "    )\n",
    "    return session\n",
    "\n",
    "\n",
    "def write_regions(ds: xr.Dataset, session: icechunk.Session, region_dict: dict):\n",
    "    commit_messages = get_commit_messages_ancestry(repo)\n",
    "    already_commited_messages = [\n",
    "        msg\n",
    "        for message in commit_messages\n",
    "        for msg in (message.split(',') if ',' in message else [message])\n",
    "    ]\n",
    "    uncommited_dict = {\n",
    "        key: subset for key, subset in region_dict.items() if key not in already_commited_messages\n",
    "    }\n",
    "    if not uncommited_dict:\n",
    "        # maybe add logging\n",
    "        warnings.warn(f'No new chunks to commit!: {uncommited_dict}')\n",
    "    else:\n",
    "        # IMPORTANT! we need to pass in subsets, not the entire dataset to get pickled.\n",
    "        ds_subsets_uncommited = [\n",
    "            ds.isel(x=x_slice, y=y_slice) for x_slice, y_slice in uncommited_dict.values()\n",
    "        ]\n",
    "\n",
    "        with session.allow_pickling():\n",
    "            tasks = [\n",
    "                insert_region(session=session, subset_ds=subset_ds)\n",
    "                for subset_ds in ds_subsets_uncommited\n",
    "            ]\n",
    "            # we could persist or w/e here\n",
    "            sessions = dask.compute(*tasks, scheduler=client)\n",
    "\n",
    "        # grabs only the dict keys / region_ids\n",
    "        region_ids = [key for key in uncommited_dict.keys()]\n",
    "        commit_region_ids = ','.join(region_ids)\n",
    "\n",
    "        session = merge_sessions(session, *sessions)\n",
    "        session.commit(f'{commit_region_ids}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f645e0a7-97e8-4a00-8e94-321aa70c7636",
   "metadata": {},
   "source": [
    "# Write CA BBOX chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6373d55f-b489-40d3-baf5-1632faffb317",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_bbox = config.bbox_from_wgs84(-125.277100, 32.374502, -113.961182, 41.951126)\n",
    "ca_chunks = config.get_chunks_for_bbox(ca_bbox)\n",
    "chunk_slices_ca = config.chunks_to_slices(ca_chunks)\n",
    "\n",
    "repo = icechunk.Repository.open(storage)\n",
    "session = repo.writable_session('main')\n",
    "write_regions(ds=ds, session=session, region_dict=chunk_slices_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b303c85-7df3-4ac4-9d54-04d8113f9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = icechunk.Repository.open(storage)\n",
    "session = repo.readonly_session('main')\n",
    "rtds = xr.open_zarr(session.store, consolidated=False, chunks={})[['BP']]\n",
    "rtds.isel(y=slice(0, 90000), x=slice(0, 120000)).coarsen(x=10, y=10, boundary='trim').mean()[\n",
    "    'BP'\n",
    "].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b08e8b-2af5-49ff-bf38-6ee248af10f2",
   "metadata": {},
   "source": [
    "## Write OR BBOX chunks \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc363cc-ecb0-4764-b0a6-0ac6f90d0522",
   "metadata": {},
   "outputs": [],
   "source": [
    "or_bbox = config.bbox_from_wgs84(-124.958496, 41.963324, -116.477051, 46.208322)\n",
    "\n",
    "or_chunks = config.get_chunks_for_bbox(or_bbox)\n",
    "chunk_slices_or = config.chunks_to_slices(or_chunks)\n",
    "\n",
    "\n",
    "repo = icechunk.Repository.open(storage)\n",
    "session = repo.writable_session('main')\n",
    "write_regions(ds=ds, session=session, region_dict=chunk_slices_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d911bc-1db9-4538-bd8e-6047b16a79c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = icechunk.Repository.open(storage)\n",
    "session = repo.readonly_session('main')\n",
    "rtds = xr.open_zarr(session.store, consolidated=False, chunks={})[['BP']]\n",
    "rtds.isel(y=slice(0, 90000), x=slice(0, 120000)).coarsen(x=10, y=10, boundary='trim').mean()[\n",
    "    'BP'\n",
    "].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5198270b-f077-4f6a-a286-82f3f4d018c9",
   "metadata": {},
   "source": [
    "### RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7cfcec-5528-4efe-a9b5-1d3bd60c1bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: can we get config to return all slices / return all chunks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b1359-5b5e-4cd0-b593-3b3aa57b8fec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
